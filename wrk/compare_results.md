# Сравнение результатов нагрузочного тестирования

## Сравнение синхронной и асинхронной реализаций

|	      | GET prev |	GET current	| PUT prev	| PUT current |	status prev	| status under put prev | status current      |	status under put current  |
|---------|----------|--------------|-----------|-------------|-------------|-----------------------|---------------------|---------------------------|
|50,000%  |	747,00us |	742,00us	| 815,00us	| 831,00us    | 1,17ms  	| 0,89ms                |	1,14ms	          | 1,02ms                    |
|75,000%  |	1,03ms   |	1,03ms		| 1,10ms	| 1,09ms	  | 1,63ms  	| 1,22ms                |	1,59ms	          | 1,42ms                    |
|90,000%  |	1,16ms   |	1,16ms		| 1,23ms	| 1,24ms	  | 2,01ms  	| 1,44ms                |	1,94ms	          | 2,03ms                    |
|99,000%  |	1,30ms   |	1,31ms		| 1,39ms	| 1,41ms	  | 2,61ms  	| 1,99ms                |	2,55ms	          | 3,80ms                    |
|99,900%  |	1,37ms   |	1,39ms		| 1,48ms	| 1,52ms	  | 3,14ms  	| 4,22ms                |	3,14ms	          | 4,76ms                    |
|99,990%  |	1,88ms   |	2,52ms		| 2,33ms	| 2,01ms	  | 3,42ms  	| 13,93ms               |	3,55ms	          | 14,56ms                   |
|99,999%  |	2,34ms   |	3,45ms		| 3,22ms	| 2,90ms	  | 3,61ms  	| 14,81ms               |	4,06ms	          | 15,14ms                   |
|100,000% |	2.34ms   |	3,45ms		| 3,22ms	| 2,90ms	  | 3,70ms  	| 14,90ms               |	4,92ms	          | 15,30ms                   |


В результате сравнения видим несколько необъяснимые явления: status сам по себе работает медленее, чем status параллельно с put.
При чем в предыдущей реализации аналогично.

Get и put в среднем работают с таким же временным интервалом.
 
По логике вещей должно было выйти следующее:
1. Status сам по себе должен работать быстрее, чем status параллельно с put.
2. При асинхронной реализации разница между временем выполнения должна была быть существенно меньше, чем при предыдущей реализации.


## Сравнение асинхронной реализации с реализаций с шардированием

|	      | GET prev |	GET current	| PUT prev	| PUT current |
|---------|----------|--------------|-----------|-------------|
|50,000%  |	742,00us |	765.00us	| 831,00us	|  788.00us   |
|75,000%  |	1,03ms	 |	1.03ms   	| 1,09ms	| 1.05ms	  |
|90,000%  |	1,16ms	 |	1.17ms	    | 1,24ms	| 1.19ms	  |
|99,000%  |	1,31ms	 |	1.44ms  	| 1,41ms	| 1.96ms	  |
|99,900%  |	1,39ms	 |	4.21ms  	| 1,52ms	| 18.58ms	  |
|99,990%  |	2,52ms	 |	7.45ms  	| 2,01ms	| 36.32ms	  |
|99,999%  |	3,45ms	 |	9.99ms  	| 2,90ms	| 39.20ms	  |
|100,000% |	3,45ms	 |	12.23ms  	| 2,90ms	| 39.36ms	  |

По результатам видно, что время обработки запросов увеличилось в обоих случаях. 
Данное явление обосновано тем, что в новой реализации с шардированием тратится определенный промежуток времени на проксирование между нодами. Что также видно при профилировании с помощью async-profiler (результаты в папке profiler/sharding).


## Сравнение реализации с шардированием с реализацией с репликами

|	      | GET prev |	GET current	| PUT prev	| PUT current |
|---------|----------|--------------|-----------|-------------|
|50,000%  |	765.00us |	 0.89ms	    |  788.00us	|  0.91ms     |
|75,000%  |	1.03ms   |	 1.14ms	    |  1.05ms	|  1.15ms  	  |
|90,000%  |	1.17ms	 |	 1.31ms     |  1.19ms	|  1.32ms  	  |
|99,000%  |	1.44ms   |	 3.15ms	    |  1.96ms	|  3.07ms  	  |
|99,900%  |	4.21ms   |	 8.90ms	    |  18.58ms	|  7.74ms  	  |
|99,990%  |	7.45ms   |	 11.02ms    |  36.32ms	|  11.26ms 	  |
|99,999%  |	9.99ms   |	 15.38m	    |  39.20ms	|  17.12ms 	  |
|100,000% |	12.23ms  |	 15.38ms	|  39.36ms	|  17.12ms 	  |

По результатам видно, что время обработки запросов увеличилось в обоих случаях. 
Данное явление обосновано тем, что в новой реализации с репликами у нас при тестировании параметр replicas был не указан, а значит использовались дефолтные значения для этого параметра, зависящие от количества нод. В нашем случае количество нод равно 3, а значит значение параметра replicas было 2/3. То есть требовалось выполнять запросы на всех 3 нодах, при этом было достаточно получить ответы от 2 из них. В связи с этим тратился определенный промежуток времени на выполнение запросов на нескольких нодах, а также на ожидание получения нескольких ответов.


## Сравнение реализации с репликами с реализацией с futures и java.net.http.HttpClient

|	      | GET prev |	GET current	| PUT prev	| PUT current |
|---------|----------|--------------|-----------|-------------|
|50,000%  |	0.89ms	 |	 1.10ms     |  0.91ms  	|   1.10ms    |
|75,000%  |	1.14ms	 |	 1.36ms     |  1.15ms  	|   1.38ms	  |
|90,000%  |	1.31ms   |	 1.62ms     |  1.32ms  	|   1.64ms	  |
|99,000%  |	3.15ms	 |	 6.19ms     |  3.07ms  	|   6.51ms	  |
|99,900%  |	8.90ms	 |	18.09ms     |  7.74ms  	|  15.82ms	  |
|99,990%  |	11.02ms  |	22.83ms     |  11.26ms 	|  24.05ms	  |
|99,999%  |	15.38m	 |	24.82ms     |  17.12ms 	|  26.13ms	  |
|100,000% |	15.38ms  |	26.19ms	    |  17.12ms 	|  26.22ms	  |

По результатам видно, что время обработки запросов увеличилось в обоих случаях.

Но мы можем посмотреть на другие данные, полученные от wrk:

|              |  requests in 30.00s | timeout   | Requests/sec   |
|--------------|---------------------|-----------|----------------|
| replicas/put |       75283         |  13653    |   2509.32      |
| futures/put  |      176934         |   5574    |   5898.24      |
|              |                     |           |                |
| replicas/get |       94245         |  13786    |   3054.92      |
| futures/get  |      145893         |   7057    |   4863.75      |

Из них видно, что пропускная способность нашего сервиса увеличилась на порядок и сократилось число таймаутов.
